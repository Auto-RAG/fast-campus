{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 비용 및 속도 평가\n",
    "## LLM 비용 측정\n"
   ],
   "id": "f3f46554bffa006f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T16:18:13.366015Z",
     "start_time": "2025-01-15T16:18:13.363666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "from openai import OpenAI"
   ],
   "id": "ba55c647ea2914c6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T16:17:11.756389Z",
     "start_time": "2025-01-15T16:17:11.740609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "5a705ddbc92b9725",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T16:17:19.383589Z",
     "start_time": "2025-01-15T16:17:19.378088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"Return the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    tokens_per_message = 3\n",
    "    tokens_per_name = 1\n",
    "\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "\n",
    "    return num_tokens"
   ],
   "id": "e407a7bb46a2562b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T16:18:47.016403Z",
     "start_time": "2025-01-15T16:18:47.008865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_tokens(messages, model=\"gpt-3.5-turbo\"):\n",
    "    # Initialize the client\n",
    "    client = OpenAI()\n",
    "    \n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # Get the output tokens\n",
    "    output_tokens = response.usage.completion_tokens\n",
    "    input_tokens = num_tokens_from_messages(messages, model=model)\n",
    "\n",
    "    return input_tokens, output_tokens\n"
   ],
   "id": "c763b7314f9db101",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T16:18:48.795985Z",
     "start_time": "2025-01-15T16:18:47.689835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like today?\"},\n",
    "]\n",
    "\n",
    "input_tokens, output_tokens = calculate_tokens(messages)\n",
    "\n",
    "print(f\"Input tokens: {input_tokens}\")\n",
    "print(f\"Output tokens: {output_tokens}\")\n",
    "print(f\"Total tokens: {input_tokens + output_tokens}\")"
   ],
   "id": "c79c680dbcf73b79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens: 24\n",
      "Output tokens: 37\n",
      "Total tokens: 61\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "[여기서](https://openai.com/api/pricing/) OpenAI API의 비용을 확인할 수 있습니다.",
   "id": "faf144b6ea2b7892"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LLM 속도 측정",
   "id": "c248ec96c51864c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T16:22:24.299746Z",
     "start_time": "2025-01-15T16:22:24.279094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "def measure_streaming_metrics(prompt):\n",
    "    start_time = time.time()\n",
    "    first_token_time = None\n",
    "    last_token_time = None\n",
    "    token_count = 0\n",
    "    total_inter_token_time = 0\n",
    "\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    for chunk in stream:\n",
    "        if token_count == 0:\n",
    "            first_token_time = time.time()\n",
    "        \n",
    "        current_time = time.time()\n",
    "        if token_count > 0:\n",
    "            total_inter_token_time += current_time - last_token_time\n",
    "        \n",
    "        last_token_time = current_time\n",
    "        token_count += len(chunk.choices[0].delta.content or \"\")\n",
    "\n",
    "    time_to_first_token = first_token_time - start_time\n",
    "    time_to_last_token = last_token_time - start_time\n",
    "    avg_inter_token_latency = total_inter_token_time / (token_count - 1) if token_count > 1 else 0\n",
    "\n",
    "    return {\n",
    "        \"time_to_first_token\": time_to_first_token,\n",
    "        \"time_to_last_token\": time_to_last_token,\n",
    "        \"avg_inter_token_latency\": avg_inter_token_latency,\n",
    "        \"total_tokens\": token_count\n",
    "    }"
   ],
   "id": "e52fcfcc52b5a452",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T16:22:30.591499Z",
     "start_time": "2025-01-15T16:22:29.789905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "prompt = \"Tell me a short joke\"\n",
    "metrics = measure_streaming_metrics(prompt)\n",
    "\n",
    "print(f\"Time to first token: {metrics['time_to_first_token']:.4f} seconds\")\n",
    "print(f\"Time to last token: {metrics['time_to_last_token']:.4f} seconds\")\n",
    "print(f\"Average inter-token latency: {metrics['avg_inter_token_latency']:.4f} seconds\")\n",
    "print(f\"Total tokens: {metrics['total_tokens']}\")"
   ],
   "id": "d70511064c0a8d7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to first token: 0.5867 seconds\n",
      "Time to last token: 0.7636 seconds\n",
      "Average inter-token latency: 0.0023 seconds\n",
      "Total tokens: 78\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c098e5a217f84f5c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
